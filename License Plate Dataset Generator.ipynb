{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c93745a-bb3d-454d-b67b-83d0866ba70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f0eaab55-f17d-4b28-ac11-17bdb161c14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('data/00918.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e0751e43-225b-451f-a518-5a8bacfd91de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_cascade = cv2.CascadeClassifier('model/haarcascade_russian_plate_number.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1534b015-9e73-4b24-823d-49c74f815489",
   "metadata": {},
   "outputs": [],
   "source": [
    "plates = plate_cascade.detectMultiScale(image, 1.1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c01346bc-9d36-44cc-a2d7-edd19f113f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2e737e34-54d7-4f26-96f8-f75f5d05a521",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y, w, h) in plates:\n",
    "    cropped_plate = image[y:y+h, x:x+w]\n",
    "    #cv2.imshow(\"Cropped Plate\", cropped_plate)\n",
    "    cv2.imwrite(\"2.jpg\", cropped_plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99860cba-112e-4901-8b5f-ff622f283c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "205ca0ae-b9b0-4512-881e-26e717257904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(\"data/plate33.jpg\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply GaussianBlur to reduce noise\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Use Canny edge detector\n",
    "edges = cv2.Canny(blurred, 100, 200)\n",
    "\n",
    "# Find contours from the edges\n",
    "contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Loop through all the contours\n",
    "for contour in contours:\n",
    "    # Approximate the contour to a polygon\n",
    "    epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "    # Check if the contour has 4 vertices (which is typical for license plates)\n",
    "    if len(approx) == 4:\n",
    "        # Get the bounding box of the contour\n",
    "        x, y, w, h = cv2.boundingRect(approx)\n",
    "\n",
    "        # Crop the license plate region\n",
    "        cropped_plate = image[y:y+h, x:x+w]\n",
    "\n",
    "        # Optionally, apply a perspective transformation if the plate is rotated\n",
    "        # For simplicity, this example does not handle the transformation here\n",
    "\n",
    "        cv2.imshow(\"Cropped Plate\", cropped_plate)\n",
    "        cv2.imwrite(\"cropped_plate323.jpg\", cropped_plate)\n",
    "\n",
    "# Display the original image with contours drawn on it\n",
    "cv2.drawContours(image, contours, -1, (0, 255, 0), 3)\n",
    "cv2.imshow(\"Image with Contours\", image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a0dabb0-1bc1-4349-9039-3e263ac29383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load YOLO model files\n",
    "net = cv2.dnn.readNet(\"model/yolov4.weights\", \"model/yolov4.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(\"data/suv.jpg\")\n",
    "height, width, channels = image.shape\n",
    "\n",
    "# Prepare the image for YOLO (blob)\n",
    "blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "\n",
    "# Set the blob as input to the network\n",
    "net.setInput(blob)\n",
    "\n",
    "# Run forward pass to get output\n",
    "outs = net.forward(output_layers)\n",
    "\n",
    "# Process the output (bounding boxes, class probabilities, etc.)\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "\n",
    "        # Filter based on confidence\n",
    "        if confidence > 0.5:  # You can adjust this threshold\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "\n",
    "            # Draw bounding box around detected license plate\n",
    "            cv2.rectangle(image, (center_x - w // 2, center_y - h // 2), \n",
    "                          (center_x + w // 2, center_y + h // 2), (0, 255, 0), 2)\n",
    "\n",
    "# Show the image with detected license plate\n",
    "cv2.imshow(\"Detected License Plate\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0a30ba9b-17ee-4350-ba16-833e201b8d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No license plate detected in the image\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def detect_and_crop_license_plate(image_path, output_path=\"cropped_plate_grok3.jpg\"):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Could not load the image\")\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Edge detection\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Filter contours to find potential license plates\n",
    "    plate_contour = None\n",
    "    max_area = 0\n",
    "    \n",
    "    for contour in contours:\n",
    "        # Approximate the contour to a polygon\n",
    "        peri = cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, 0.02 * peri, True)\n",
    "        \n",
    "        # Check if the contour has 4 sides (rectangle) and reasonable area\n",
    "        area = cv2.contourArea(contour)\n",
    "        if len(approx) == 4 and 500 < area < 50000:  # Adjust area range as needed\n",
    "            # Check aspect ratio (typical license plate is wider than tall)\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            aspect_ratio = float(w) / h\n",
    "            if 1.5 < aspect_ratio < 5.0:  # Typical license plate aspect ratio\n",
    "                if area > max_area:\n",
    "                    max_area = area\n",
    "                    plate_contour = approx\n",
    "    \n",
    "    if plate_contour is None:\n",
    "        raise ValueError(\"No license plate detected in the image\")\n",
    "    \n",
    "    # Get bounding rectangle coordinates\n",
    "    x, y, w, h = cv2.boundingRect(plate_contour)\n",
    "    \n",
    "    # Add padding to ensure full plate is captured\n",
    "    padding = 10\n",
    "    x = max(0, x - padding)\n",
    "    y = max(0, y - padding)\n",
    "    w = min(image.shape[1] - x, w + 2 * padding)\n",
    "    h = min(image.shape[0] - y, h + 2 * padding)\n",
    "    \n",
    "    # Crop the license plate\n",
    "    plate_image = image[y:y+h, x:x+w]\n",
    "    \n",
    "    # Optional: Apply perspective transform if plate is skewed\n",
    "    pts = plate_contour.reshape(4, 2)\n",
    "    rect = order_points(pts)\n",
    "    max_width = max(int(np.linalg.norm(rect[0] - rect[1])), int(np.linalg.norm(rect[2] - rect[3])))\n",
    "    max_height = max(int(np.linalg.norm(rect[0] - rect[3])), int(np.linalg.norm(rect[1] - rect[2])))\n",
    "    \n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [max_width - 1, 0],\n",
    "        [max_width - 1, max_height - 1],\n",
    "        [0, max_height - 1]], dtype=\"float32\")\n",
    "    \n",
    "    # Compute perspective transform\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (max_width, max_height))\n",
    "    \n",
    "    # Save both the simple crop and perspective-corrected version\n",
    "    cv2.imwrite(output_path, warped)\n",
    "    cv2.imwrite(\"simple_crop_\" + output_path, plate_image)\n",
    "    \n",
    "    return True\n",
    "\n",
    "def order_points(pts):\n",
    "    # Order points in a rectangle (top-left, top-right, bottom-right, bottom-left)\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    \n",
    "    # Sum and difference of x and y coordinates\n",
    "    s = pts.sum(axis=1)\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    \n",
    "    rect[0] = pts[np.argmin(s)]  # Top-left (min sum)\n",
    "    rect[2] = pts[np.argmax(s)]  # Bottom-right (max sum)\n",
    "    rect[1] = pts[np.argmin(diff)]  # Top-right (min diff)\n",
    "    rect[3] = pts[np.argmax(diff)]  # Bottom-left (max diff)\n",
    "    \n",
    "    return rect\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Replace with your image path\n",
    "        input_image = \"data/suv.jpg\"\n",
    "        output_image = \"cropped_plate_grok5.jpg\"\n",
    "        \n",
    "        success = detect_and_crop_license_plate(input_image, output_image)\n",
    "        if success:\n",
    "            print(f\"License plate successfully cropped and saved as {output_image}\")\n",
    "            print(f\"Simple crop saved as simple_crop_{output_image}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "445f2f1a-6016-4410-bf05-7db882d4c2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dimensions: 600x433\n",
      "Classes: ['license_plate', 'license plate']\n",
      "Error: list index out of range\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_yolo_model(weights_path, config_path, names_path):\n",
    "    net = cv2.dnn.readNet(weights_path, config_path)\n",
    "    with open(names_path, \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    return net, classes, output_layers\n",
    "\n",
    "def detect_and_crop_license_plate(image_path, weights_path, config_path, names_path, output_path=\"cropped_plate.jpg\", confidence_threshold=0.5):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Could not load the image\")\n",
    "    \n",
    "    height, width = image.shape[:2]\n",
    "    print(f\"Image dimensions: {width}x{height}\")\n",
    "    \n",
    "    # Load YOLO model\n",
    "    net, classes, output_layers = load_yolo_model(weights_path, config_path, names_path)\n",
    "    print(f\"Classes: {classes}\")\n",
    "    \n",
    "    # Prepare image for YOLO\n",
    "    blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    \n",
    "    # Perform detection\n",
    "    outputs = net.forward(output_layers)\n",
    "    \n",
    "    # Process detections\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "    \n",
    "    for output in outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            \n",
    "            if confidence > confidence_threshold:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                \n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "                print(f\"Detected: Class={classes[class_id]}, Confidence={confidence}, Box=[{x}, {y}, {w}, {h}]\")\n",
    "    \n",
    "    if not boxes:\n",
    "        raise ValueError(\"No objects detected above confidence threshold\")\n",
    "    \n",
    "    # Apply Non-Max Suppression\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, confidence_threshold, 0.4)\n",
    "    print(f\"NMS indices: {indices}\")\n",
    "    \n",
    "    if len(indices) == 0:\n",
    "        raise ValueError(\"No license plate detected after NMS\")\n",
    "    \n",
    "    # Get the best detection\n",
    "    idx = indices[0]  # Take the first detection\n",
    "    box = boxes[idx]\n",
    "    x, y, w, h = box\n",
    "    print(f\"Selected box: [{x}, {y}, {w}, {h}]\")\n",
    "    \n",
    "    # Add padding and ensure coordinates are within image bounds\n",
    "    padding = 10\n",
    "    x = max(0, x - padding)\n",
    "    y = max(0, y - padding)\n",
    "    w = min(width - x, w + 2 * padding)\n",
    "    h = min(height - y, h + 2 * padding)\n",
    "    print(f\"Adjusted box with padding: [{x}, {y}, {w}, {h}]\")\n",
    "    \n",
    "    # Crop the license plate\n",
    "    plate_image = image[y:y+h, x:x+w]\n",
    "    if plate_image.size == 0:\n",
    "        raise ValueError(\"Cropped image is empty - invalid coordinates\")\n",
    "    \n",
    "    # Save the cropped image\n",
    "    cv2.imwrite(output_path, plate_image)\n",
    "    print(f\"Cropped image shape: {plate_image.shape}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        input_image = \"data/suv.jpg\"\n",
    "        output_image = \"cropped_plate123.jpg\"\n",
    "        weights_path = \"model/yolov4.weights\"\n",
    "        config_path = \"model/yolov4.cfg\"\n",
    "        names_path = \"model/coco.names\"\n",
    "        \n",
    "        success = detect_and_crop_license_plate(\n",
    "            input_image,\n",
    "            weights_path,\n",
    "            config_path,\n",
    "            names_path,\n",
    "            output_image,\n",
    "            confidence_threshold=0.5\n",
    "        )\n",
    "        if success:\n",
    "            print(f\"License plate successfully cropped and saved as {output_image}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a11ced0-7522-4beb-a339-caca56f75d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
